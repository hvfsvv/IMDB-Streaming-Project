from pyspark.sql import functions as F
from pyspark.sql.utils import AnalysisException

# Define the Managed Unity Catalog Table NAMES
UC_TABLE_METRICS = "workspace.imdb_project.stream_metrics_output"
UC_TABLE_ALERTS = "workspace.imdb_project.stream_alerts_output"

print("--- VERIFYING AGGREGATED METRICS (UC TABLE) ---")
try:
    # Read directly from the UC table by name
    df_metrics_result = spark.table(UC_TABLE_METRICS)
    print(f"Total processed metric windows: {df_metrics_result.count():,}")
    
    # Display the top 10 rows, sorted by edit count
    df_metrics_result.orderBy(F.col("edit_count").desc()).show(10, truncate=False)
    
except AnalysisException as e:
    print(f" METRICS READING FAILED: The table '{UC_TABLE_METRICS}' might not exist yet, or permissions are missing.")
    print(f"Error: {e.desc}")
except Exception as e:
    print(f" METRICS READING FAILED. Error: {e}")
    
print("\n--- VERIFYING TRIGGERED ALERTS (UC TABLE) ---")
try:
    # Read directly from the UC table by name
    df_alerts_result = spark.table(UC_TABLE_ALERTS)
    print(f"Total triggered alerts: {df_alerts_result.count():,}")
    
    # Display the alerts
    df_alerts_result.show(10, truncate=False)
    
except AnalysisException as e:
    print(f" ALERTS READING FAILED: The table '{UC_TABLE_ALERTS}' might not exist yet, or permissions are missing.")
    print(f"Error: {e.desc}")
except Exception as e:
    print(f" ALERTS READING FAILED. Error: {e}")
     
